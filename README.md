# Projects

# Professional Portfolio Website 
https://khushigupta.mystrikingly.com/

# Certificates
1. Python for Data Science: https://drive.google.com/file/d/1K-8r54BNAhLvzH7X_o48kx8yIAq1XVmR/view?usp=sharing
2. Career Essentials in Generative AI by LinkedIn & Microsoft: https://drive.google.com/file/d/10o5SYdj9jKpjz70AK77nDQlMRwDnYD5Q/view?usp=sharing

# Small Prototype of RAG

When I started learning about Retrieval-Augmented Generation (RAG), I developed a small prototype to practice and understand its core components. The prototype integrates two key models: DPR (Dense Passage Retrieval) for retrieving relevant context based on a given query and BART (Bidirectional and Auto-Regressive Transformers) for generating answers based on the retrieved context. I used a simple set of example passages and encoded them into context embeddings. For a query, the system retrieves the closest matching context using DPR's dot product similarity, and then BART generates an answer by combining the query and the retrieved context. This prototype allowed me to get hands-on experience with how RAG systems work and helped deepen my understanding of retrieval and generation tasks.

FOR MORE DETAILS CHECK OUT: https://github.com/khushigupta20/Small-Prototype-of-RAG

# RAG

When I started exploring advanced document retrieval and question-answering techniques, I built a prototype to deepen my understanding of vector-based retrieval and generation models. This project integrates Llama Index, LangChain, and Hugging Faceâ€™s LLaMA-2 model, providing hands-on experience in creating context-aware responses. I indexed a set of example documents into vector embeddings, allowing the system to retrieve relevant contexts based on similarity to a given query. With the closest matching context retrieved, the LLaMA-2 model generates a tailored response by conditioning on both the query and retrieved context. Developing this prototype helped me grasp the core mechanics of vector-based retrieval and how to effectively leverage large language models for accurate, coherent answers in open-domain Q&A tasks.

FOR MORE DETAILS CHECK OUT: https://github.com/khushigupta20/RAG

# Code Optimizer

This project involves developing a Python-based Code Optimizer tool aimed at analyzing and enhancing code efficiency by identifying areas for improvement. The tool leverages Python libraries such as ast (Abstract Syntax Trees) to parse and analyze the structure of the input code. It identifies potential inefficiencies, such as redundant operations, unused variables, and suboptimal loop structures, and provides recommendations for optimization. Additionally, the project includes mechanisms to ensure the optimized code maintains functional equivalence with the original. This project demonstrates the application of advanced code analysis techniques to improve software performance and reliability, making it a valuable resource for developers seeking to refine their coding practices.

FOR MORE DETAILS CHECK OUT: https://github.com/khushigupta20/code_optimizer

# Wikipedia Page Web Scrapper

This project involves developing a Python-based web scraper that extracts detailed information about the members of the 17th Lok Sabha from a Wikipedia page and stores the data in a structured format. Utilizing `requests` for HTTP requests and `BeautifulSoup` for parsing HTML content, the script navigates through the table of members on the Wikipedia page and extracts key information, including Constituency, Name, Party & a hyperlink to each member's profile. The script efficiently handles variations in the table structure, such as rows with merged cells or vacant entries, ensuring accurate data collection. Once the data is extracted, it is stored in a CSV file, allowing for easy access and further analysis. The CSV file includes headers for the key attributes of each member, providing a structured and organized dataset for future use. This project demonstrates the application of web scraping techniques and data processing for collecting publicly available information and converting it into a usable format.

FOR MORE DETAILS CHECK OUT: https://github.com/khushigupta20/-Wikipedia-Page-Web-Scrapper

# Dataset Extraction from Pubmed Central 

This project is a Python-based automation tool designed to retrieve and process research articles from PubMed Central (PMC) using the NCBI E-utilities API. It efficiently queries articles based on a user-defined search term, extracts essential details such as titles, links, article types, and supplementary datasets, and saves the information in a structured CSV format. Additionally, the tool filters articles to highlight those containing supplementary materials, making it highly useful for researchers seeking to automate the collection of relevant publications and associated datasets for further analysis and research.

FOR MORE DETAILS CHECK OUT: https://github.com/khushigupta20/Dataset-Extraction-from-Pubmed-Central-

# Air Gesture 

The Gesture Controlled Air-Canvas project enables users to perform tasks using hand gestures in a virtual space. Utilizing MediaPipe and OpenCV, it allows for activities like free-style drawing and controlling presentations without traditional devices. The system enhances accessibility for individuals with physical disabilities and incorporates 3D drawing capabilities, enriching user interaction. This innovative platform represents a significant advancement in human-computer interaction, promoting artistic expression and educational engagement through intuitive gesture controls.

FOR MORE DETAILS CHECK OUT: https://github.com/khushigupta20/-AnimArt-From-Hand-Waves-to-Animated-Wonders
